{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 导入数据\n",
    "* 数据文件与该文件放在同一文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "d_gen=pd.read_csv('GEN-sarc-notsarc.csv')\n",
    "d_hyp=pd.read_csv('HYP-sarc-notsarc.csv')\n",
    "d_rq=pd.read_csv('RQ-sarc-notsarc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置标签 讽刺为1 非讽刺为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1=d_gen[\"text\"]\n",
    "text2=d_hyp[\"text\"]\n",
    "text3=d_rq[\"text\"]\n",
    "lable1=[1]*len(text1)\n",
    "lable2=[0]*len(text2)\n",
    "lable3=[0]*len(text3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=[]\n",
    "labels=[]\n",
    "\n",
    "texts.extend(text1)\n",
    "texts.extend(text2)\n",
    "texts.extend(text3)\n",
    "\n",
    "labels.extend(lable1)\n",
    "labels.extend(lable2)\n",
    "labels.extend(lable3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用Keras的Tokenizer对句子进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer  \n",
    "# from keras.preprocessing.sequence import pad_sequences  \n",
    "# 将上面替换为下面\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "  \n",
    "# 初始化 Tokenizer 并拟合文本数据  \n",
    "tokenizer = Tokenizer(num_words=10000)  # 假设我们只想保留最常见的10000个单词  \n",
    "tokenizer.fit_on_texts(texts)  \n",
    "  \n",
    "# 将文本转换为序列  \n",
    "sequences = tokenizer.texts_to_sequences(texts)  \n",
    "  \n",
    "# 填充/截断序列，使其具有相同的长度  \n",
    "max_len = max([len(seq) for seq in sequences])  \n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post')  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 使用Keras构建一个基于LSTM的讽刺检测模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 288s 1s/step - loss: 0.6184 - accuracy: 0.6950 - val_loss: 0.6202 - val_accuracy: 0.6933\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 269s 1s/step - loss: 0.6158 - accuracy: 0.6950 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 253s 1s/step - loss: 0.6164 - accuracy: 0.6950 - val_loss: 0.6168 - val_accuracy: 0.6933\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 244s 1s/step - loss: 0.6163 - accuracy: 0.6950 - val_loss: 0.6171 - val_accuracy: 0.6933\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 252s 1s/step - loss: 0.6159 - accuracy: 0.6950 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 255s 1s/step - loss: 0.6161 - accuracy: 0.6950 - val_loss: 0.6169 - val_accuracy: 0.6933\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 251s 1s/step - loss: 0.6159 - accuracy: 0.6950 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 247s 1s/step - loss: 0.6160 - accuracy: 0.6950 - val_loss: 0.6191 - val_accuracy: 0.6933\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 252s 1s/step - loss: 0.6155 - accuracy: 0.6950 - val_loss: 0.6173 - val_accuracy: 0.6933\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 241s 1s/step - loss: 0.6159 - accuracy: 0.6950 - val_loss: 0.6165 - val_accuracy: 0.6933\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 0.6165 - accuracy: 0.6933\n",
      "Test accuracy: 0.6933\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential  \n",
    "from keras.layers import Embedding, LSTM, Dense  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "  \n",
    "# padded_sequences 是序列，labels 是对应的标签  \n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)  \n",
    "  \n",
    "# 定义模型  \n",
    "model = Sequential()  \n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len))  \n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))  \n",
    "model.add(Dense(1, activation='sigmoid'))   \n",
    "  \n",
    "# 编译模型  \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
    "\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# 训练模型  \n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)  \n",
    "  \n",
    "# 评估模型  \n",
    "_, accuracy = model.evaluate(X_test, y_test)  \n",
    "print(f'Test accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 保存tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer  \n",
    "import json  \n",
    "  \n",
    "# 保存 Tokenizer 的词汇表  \n",
    "with open('tokenizer.json', 'w', encoding='utf-8') as f:  \n",
    "    tokenizer_json = tokenizer.to_json()  \n",
    "    f.write(tokenizer_json)  \n",
    "\n",
    "# 将 Tokenizer 配置转换为 JSON 字符串  \n",
    "tokenizer_config = tokenizer.to_json() \n",
    "\n",
    "# 将 JSON 字符串保存到文件  \n",
    "with open('tokenizer_config.json', 'w', encoding='utf-8') as f:  \n",
    "    f.write(tokenizer_config) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 386ms/step\n",
      "['非讽刺', '非讽刺']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model  \n",
    "from keras.preprocessing.text import tokenizer_from_json  \n",
    "import numpy as np  \n",
    "  \n",
    "# # 加载保存的 Tokenizer 配置  \n",
    "# with open('tokenizer.json', 'r', encoding='utf-8') as f:  \n",
    "#     tokenizer_json = json.load(f)  \n",
    "#     loaded_tokenizer = tokenizer_from_json(tokenizer_json)  \n",
    "\n",
    "# 加载整个模型（包括结构和权重）  \n",
    "model = load_model('my_model.h5')  \n",
    "\n",
    "# from keras.preprocessing.sequence import pad_sequences  \n",
    "\n",
    "# new_texts是你想要预测的新文本  \n",
    "new_texts = [\"If that's true, then Freedom of Speech is doomed. Harassment is subjective. Now I can claim that a book I don't like is harassing me, and it will be banned.\",\"Neener neener - is it time to go in from the playground yet?\"]  \n",
    "new_sequences = tokenizer.texts_to_sequences(new_texts)  \n",
    "new_padded_sequences = pad_sequences(new_sequences, maxlen=max_len)\n",
    "\n",
    "# 进行预测  \n",
    "predictions = model.predict(new_padded_sequences)  \n",
    "\n",
    "# 对于分类问题，如果输出层使用了softmax，你可能需要取概率最高的类别  \n",
    "predicted_classes = np.argmax(predictions, axis=1)  \n",
    "\n",
    "# 如果你的标签是整数编码的，你可能需要将这些整数转换回原始的标签名  \n",
    "label_to_name = {0: '非讽刺', 1: '讽刺'}  # 假设你有一个这样的映射  \n",
    "predicted_labels = [label_to_name[cls] for cls in predicted_classes]\n",
    "\n",
    "print(predicted_labels)\n",
    "# from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "# # 假设y_true是真实标签  \n",
    "# accuracy = accuracy_score(y_true, predicted_classes)  \n",
    "# report = classification_report(y_true, predicted_classes)  \n",
    "\n",
    "# print(f'Accuracy: {accuracy:.4f}')  \n",
    "# print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
